{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('input/train_preprocessed.csv', delimiter=',')\n",
    "test_data = pd.read_csv('input/test_preprocessed.csv', delimiter=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.loc[:, train_data.columns[:-1]].values\n",
    "y_train = train_data.loc[:, 'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc_cross_val(model, n_folds, x, y):\n",
    "    k_f = KFold(n_folds, random_state=11, shuffle=True).get_n_splits(x)\n",
    "    auc_roc = cross_val_score(model, x, y, scoring=\"roc_auc\", cv = k_f)\n",
    "    return auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost = GradientBoostingClassifier(n_estimators=2500, learning_rate=0.005,\n",
    "                                   max_depth=35, max_features='sqrt',\n",
    "                                   min_samples_leaf=35, min_samples_split=20, \n",
    "                                   loss='exponential', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " grad_boost score: 0.8630 (0.0164)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(grad_boost, 5,  x_train, y_train)\n",
    "print(\"\\n grad_boost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "#0.8639\n",
    "#8638 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(StandardScaler(), Lasso(alpha =0.1e-1, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lasso score: 0.8426 (0.0280)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(lasso, 5,  x_train, y_train)\n",
    "print(\"\\n lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "#0.8426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = make_pipeline(StandardScaler(), LogisticRegression(C=3e-3, penalty='l2',solver='lbfgs', random_state=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " log score: 0.8448 (0.0346)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(log, 5,  x_train, y_train)\n",
    "print(\"\\n log score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "#8447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " svm score: 0.8474 (0.0223)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = make_pipeline(StandardScaler(),SVC(C=1.0, gamma='scale', random_state=22))\n",
    "score = auc_roc_cross_val(svm, 5,  x_train, y_train)\n",
    "print(\"\\n svm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(StandardScaler(), RidgeClassifier(alpha=2500,  solver='auto', random_state=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ridge score: 0.8211 (0.0296)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(ridge, 5,  x_train, y_train)\n",
    "print(\"\\n ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=2000, max_depth=10, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   random_state =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " rand_forest score: 0.8484 (0.0251)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(rand_forest, 5,  x_train, y_train)\n",
    "print(\"\\n rand_forest score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " knn score: 0.8271 (0.0329)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = auc_roc_cross_val(knn, 5, x_train, y_train)\n",
    "print(\"\\n knn score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingModels(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.base_models_ = [list() for _ in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        \n",
    "        k_f = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        meta_features = np.zeros([x.shape[0], len(self.base_models)])\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train, test in k_f.split(x, y):\n",
    "                base_model = clone(model)\n",
    "                self.base_models_[i].append(base_model)\n",
    "                base_model.fit(x[train], y[train])\n",
    "                y_pred = base_model.predict(x[test])\n",
    "                meta_features[test, i] = y_pred\n",
    "                \n",
    "        \n",
    "        self.meta_model.fit(meta_features, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        meta_features = np.array([\n",
    "            np.array([model.predict(x) for model in base_models]).mean(axis=0) \n",
    "            for base_models in self.base_models_\n",
    "        ]).transpose()\n",
    "        y_pred = self.meta_model.predict(meta_features)\n",
    "        return y_pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_models = StackingModels(\n",
    "    base_models=(\n",
    "        SVC(C=1.0, gamma='scale', random_state=22),\n",
    "        GradientBoostingClassifier(n_estimators=2500, learning_rate=0.005,\n",
    "                                   max_depth=35, max_features='sqrt',\n",
    "                                   min_samples_leaf=35, min_samples_split=20,\n",
    "                                   loss='exponential', random_state=5),\n",
    "        LogisticRegression(C=3e-3, penalty='l2', solver='lbfgs', random_state=5),\n",
    "    ),\n",
    "    meta_model=Lasso(alpha =1e-2, random_state=3))\n",
    "\n",
    "stacking_models_pipe = make_pipeline(StandardScaler(),stacking_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_local_train, x_val, y_local_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_models_pipe.fit(x_local_train, y_local_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8382716049382717"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stacking_models_pipe.predict(x_val)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingModels(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(x, y)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = np.array([model.predict(x) for model in self.models_])\n",
    "        return np.mean(predictions, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_models = BoostingModels([\n",
    "        SVC(C=1.0, gamma='scale', random_state=22),\n",
    "        GradientBoostingClassifier(n_estimators=2500, learning_rate=0.005,\n",
    "                                   max_depth=35, max_features='sqrt',\n",
    "                                   min_samples_leaf=35, min_samples_split=20,\n",
    "                                   loss='exponential', random_state=5),\n",
    "        LogisticRegression(C=3e-3, penalty='l2', solver='lbfgs', random_state=5),\n",
    "        Lasso(alpha =0.1e-1, random_state=3),\n",
    "])\n",
    "\n",
    "boosting_models_pipe = make_pipeline(StandardScaler(), boosting_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_models_pipe.fit(x_local_train, y_local_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8629629629629629"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = boosting_models_pipe.predict(x_val)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_clf():\n",
    "    neural_net = Sequential()\n",
    "    neural_net.add(Dense(128, kernel_initializer='random_normal'))\n",
    "    neural_net.add(BatchNormalization())\n",
    "    neural_net.add(Activation('relu'))\n",
    "    neural_net.add(Dropout(0.5))\n",
    "    neural_net.add(Dense(128, kernel_initializer='random_normal'))\n",
    "    neural_net.add(BatchNormalization())\n",
    "    neural_net.add(Activation('relu'))\n",
    "    neural_net.add(Dropout(0.5))\n",
    "    neural_net.add(Dense(128, kernel_initializer='random_normal'))\n",
    "    neural_net.add(BatchNormalization())\n",
    "    neural_net.add(Activation('relu'))\n",
    "    neural_net.add(Dropout(0.5))\n",
    "    neural_net.add(Dense(128, kernel_initializer='random_normal'))\n",
    "    neural_net.add(BatchNormalization())\n",
    "    neural_net.add(Activation('relu'))\n",
    "    neural_net.add(Dropout(0.5))\n",
    "    neural_net.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    neural_net.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_neural_networks = BoostingModels([\n",
    "        KerasClassifier(keras_clf, epochs=90, batch_size=50, verbose=0),\n",
    "        KerasClassifier(keras_clf, epochs=95, batch_size=50, verbose=0),\n",
    "        KerasClassifier(keras_clf, epochs=95, batch_size=50, verbose=0),\n",
    "        KerasClassifier(keras_clf, epochs=100, batch_size=50, verbose=0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_neural_networks_pipe = make_pipeline(StandardScaler(), boosting_neural_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xryash/anaconda3/envs/tensorflow-gpu-starter/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xryash/anaconda3/envs/tensorflow-gpu-starter/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xryash/anaconda3/envs/tensorflow-gpu-starter/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('gpu:0'):\n",
    "    boosting_neural_networks_pipe.fit(x_local_train, y_local_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910052910052909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = boosting_neural_networks_pipe.predict(x_val)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = stacking_models_pipe.predict(x_val)\n",
    "bm_pred = boosting_models_pipe.predict(x_val)\n",
    "bnn_pred = np.reshape(boosting_neural_networks_pipe.predict(x_val),[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((219,), (219,), (219,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sm_pred.shape, bm_pred.shape, bnn_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_class(arr):\n",
    "    arr[arr < 0] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bm_pred * 0.5 + sm_pred * 0.3 + bnn_pred * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626102292768959"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_class(y_pred)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_models_pipe.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_models_pipe.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_neural_networks_pipe.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194, 1550), (1095, 1550))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test_data.values\n",
    "(x_test.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = stacking_models_pipe.predict(x_test)\n",
    "bm_pred = boosting_models_pipe.predict(x_test)\n",
    "bnn_pred = np.reshape(boosting_neural_networks_pipe.predict(x_test),[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = bm_pred * 0.6 + sm_pred * 0.2 + bnn_pred * 0.2\n",
    "final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['sample_id'] = test_data.index\n",
    "sub['y'] = final_pred\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
